 I read an extra of an assignment. A watch T-test was conducted to prepare sample efficiency with the null hypothesis H0 stating that the min steps to convergence are equal for both models. The results are Maze 3x3 H0 cannot be rejected with 90% of confidence. Figure 1 shows nearly identical min steps for both models. Maze 5x5. H0 is rejected with 95% of confidence. Dynacue is more efficient, so figure 1 shows some overlap in error bounds, indicating rational comparable performance by cure learning. Maze 8x8. H0 is rejected with 87% of confidence. Dynacue is more efficient, with narrow error bounds in figure 1. Dynacue demonstrates superior sample efficiency, particularly in larger mases. For smaller mases, it's advantage diminishes due to minimal real interactions required.