 I read an extra of an assignment. A Welsh tea test was conducted to prepare sample efficiency with the null hypothesis H0 stating that the min steps to convergence are equal for both models. The results are mains 3x3, H0 cannot be rejected with 90% of confidence. Figure 1 shows nearly identical min steps for both models. Mace 5x5, H0 is rejected with 95% of confidence. Dinocue is more efficient, so figure 1 shows some overlap in error bounds, indicating rational comparable performance by cure learning. Mace 8x8, H0 is rejected with 87% of confidence. Dinocue is more efficient, with narrow error bounds in figure 1. Dinocue demonstrates a very simple efficiency, particularly in larger mazes. For smaller mazes, it's advantage diminishes due to minimal real interactions required.