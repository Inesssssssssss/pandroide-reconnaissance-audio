 I read an extra of an assignment, a watch T-Best was conducted to prepare some of efficiency with the null hypothesis H0 stating that the mean steps to convergence are equal for both models. The results are mains 3x3, H0 cannot be rejected with 90% of confidence. Figure 1 shows nearly identical mean steps for both models. Mace 5x5, H0 is rejected with 95% of confidence. Tynacue is more efficient, so figure 1 shows some overlap in error bounds, indicating occasional comparable performance by Q-learning. Mace operates, H0 is rejected with 87% of confidence. Tynacue is more efficient, with null error bounds in figure 1. Tynacue demonstrates a very simple efficiency, particularly in larger mazes. For smaller mazes, it's advantage diminishes due to minimal real interactions to the client.