 I'll read an extra of an assignment. A Welch's T-test was conducted to compare some of efficiency with the null hypothesis H0 stating that the mean steps to convergence are equal for both models. The results are, mains super3 H0 cannot be rejected with 90% of confidence. Figure 1 shows nearly identical mean steps for both models. Maze 5-5. H0 is rejected with 95% of confidence. TinyQ is more efficient. So Figure 1 shows some overlap in error bounds, indicating cashier comparable performance by cure learning. Maze 8-8. H0 is rejected with 87% of confidence. TinyQ is more efficient, with narrow error bounds in Figure 1. TinyQ demonstrates a very simple efficiency, particularly in larger ranges. For smaller ranges, it's advantage diminishes due to minimal real interactions to the client.